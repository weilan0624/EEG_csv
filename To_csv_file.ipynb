{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyedflib\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install pickle\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import *\n",
    "import pandas\n",
    "import pickle\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple channels to single channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows plots to appear directly in the notebook.\n",
    "%matplotlib inline\n",
    "#data_path='D:/EEG/EDF/Crumlin/try_separate/identify_AGE/6/train/'\n",
    "# Load the edf file\n",
    "f = pyedflib.EdfReader(\"6-22.edf\")\n",
    "n = f.signals_in_file\n",
    "signal_labels = f.getSignalLabels()\n",
    "sigbufs = np.zeros((n, f.getNSamples()[0]))\n",
    "\n",
    "for i in np.arange(n):\n",
    "    sigbufs[i, :] = f.readSignal(i)\n",
    "\n",
    "# and load the data into a DataFrame\n",
    "df_signals = pd.DataFrame(sigbufs)\n",
    "df_signals = df_signals.transpose()\n",
    "df_signals.columns = signal_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The sample frequency of your data is: ', f.getSampleFrequency(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now convert the edf format to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signals.columns=['EEG1','EEG2']\n",
    "signal_channel=df_signals.EEG2\n",
    "path='D:/Desktop/Deployment-flask-master/'\n",
    "signal_channel=pd.DataFrame(signal_channel)\n",
    "signal_channel.columns=['EEG']\n",
    "signal_channel=signal_channel[14400000:16200000]\n",
    "signal_channel.to_csv(path+'EEG_6_22_8-9h.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bio-channel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelHeader:\n",
    "    def __init__(self,seq,name):\n",
    "        self.seq = seq\n",
    "        self.name = name\n",
    "        self.offset_in_chunk = -1\n",
    "        self.sample_rate = -1\n",
    "        #chunk_size means number of elements in one chunk\n",
    "        self.chunk_size = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8 \n",
    "# Input\n",
    "#   edf_filename: full path name of EDF file\n",
    "# Return\n",
    "#   data_map: key=channel_name, value=data list\n",
    "#   cHdrList: header info of each channel\n",
    "def readRawDataFromEdf(edf_filename):\n",
    "    with io.open(edf_filename, 'rb') as f:\n",
    "        cHdrList = readHeader(f)\n",
    "        #DEBUG\n",
    "        chunk_size = 0\n",
    "        for cHdr in cHdrList:\n",
    "            print (\"%s, sample_rate=%d\" % (cHdr.name, cHdr.sample_rate))\n",
    "            chunk_size = chunk_size + cHdr.sample_rate\n",
    "        print (\"total bytes in one chunk: %d\" % ((2*chunk_size)))\n",
    "        data_map = readData(f, cHdrList)\n",
    "  \n",
    "    return data_map,cHdrList\n",
    "\n",
    "#read header information from EDF file stream\n",
    "#INPUT f: handle to EDF file, caller must gurantee the position is set to START of the file\n",
    "#RETURN cHdrList: a list, each element represent a channel\n",
    "def readHeader(f):\n",
    "    f.seek(243,io.SEEK_CUR)\n",
    "    chunk_time_len = int(f.read(8))\n",
    "    #print chunk_time_len\n",
    "    num_of_channels = int(f.read(4))\n",
    "    #print num_of_channels\n",
    "    \n",
    "    #read num_of_channels*16 byte for names\n",
    "    cHdrList = []\n",
    "    for cid in range(num_of_channels):\n",
    "        channel_name = str(f.read(16)).strip()\n",
    "        cHdrList.append(ChannelHeader(cid, channel_name))\n",
    "    \n",
    "    #Skip data until sample rate\n",
    "    f.seek(num_of_channels*200, io.SEEK_CUR)\n",
    "    \n",
    "    #read sample rate of each channel\n",
    "    offset = 0\n",
    "    for cid in range(num_of_channels):\n",
    "        chunk_size = int(f.read(8))\n",
    "        cHdrList[cid].offset_in_chunk = offset\n",
    "        cHdrList[cid].chunk_size = chunk_size\n",
    "        cHdrList[cid].sample_rate = chunk_size / chunk_time_len\n",
    "\n",
    "    #skip reserved field\n",
    "    f.seek(num_of_channels*32 + 1, io.SEEK_CUR)\n",
    "  \n",
    "    return cHdrList\n",
    "\n",
    "#read data from EDF file, each data is a 16 bits integer with sign\n",
    "#INPUT f: handle to EDF file, caller must gurantee the position is set to START + (num_of_channel + 1 )*256, i.e. the start position of data section\n",
    "#RETURN data_map: key=channel_name, value=data list\n",
    "def readData(f, cHdrList):\n",
    "    #prepare the result data\n",
    "    data_map = {}\n",
    "    for cHdr in cHdrList:\n",
    "        data_map[cHdr.name]=[]\n",
    "  \n",
    "    #read each channel \n",
    "    eof = False\n",
    "    chunk_cnt = 0\n",
    "    while True:\n",
    "        for cHdr in cHdrList:\n",
    "        #read data for only one channel in one chunk\n",
    "            for dataIdx in range(cHdr.chunk_size):\n",
    "                data_array = f.read(2)\n",
    "            #DEBUG\n",
    "            #print data_array.encode('hex')\n",
    "                if (len(data_array) == 0):\n",
    "                    eof = True\n",
    "                    break\n",
    "                #unpack using little-endian\n",
    "                data = struct.unpack('<h', data_array)[0]\n",
    "                data_map[cHdr.name].append(data)\n",
    "      \n",
    "            if eof:\n",
    "                break\n",
    "    \n",
    "        chunk_cnt = chunk_cnt +1\n",
    "        if eof:    \n",
    "            print (\"Chunk_count = %d\" % (chunk_cnt))\n",
    "            break\n",
    "  \n",
    "    return data_map  \n",
    "\n",
    "def writeDataIntoDisk(filename, dataList):\n",
    "    with open(filename,'w') as f:\n",
    "        for data in dataList:\n",
    "            f.write(\"%d,\" % data)\n",
    "\n",
    "def ensureUtf(s):\n",
    "    try:\n",
    "        if type(s) == unicode:\n",
    "            return s.encode('utf8', 'ignore')\n",
    "    except: \n",
    "        return str(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename =ensureUtf(\"D:/desk/EEG/mouse/Rogerio_data/Lan-data/P24_b_M1.edf\")\n",
    "data_map,cHdrList = readRawDataFromEdf(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: sample rate is your sample frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame.from_dict(data_map, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.transpose()\n",
    "df.columns = ['C3','C4','CZ','F3','F4','F7','F8','FZ','FP1','FP2','FPZ','O1','O2','P3','P4','PZ','T3','T4','T5','T6','AUX1',\n",
    "              'AUX2','AUX3','AUX4','AUX5','AUX6','AUX7','AUX8','PG1' ,'PG2' ,'A1','A2','EDF Annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T6_P4=df['T6']-df['P4']\n",
    "O2_P4=df['O2']-df['P4']\n",
    "F7_F3=df['F7']-df['F3']\n",
    "C3_F3=df['C3']-df['F3']\n",
    "F8_F4=df['F8']-df['F4']\n",
    "C4_F4=df['C4']-df['F4']\n",
    "T5_P3=df['T5']-df['P3']\n",
    "O1_P3=df['O1']-df['P3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [T6_P4,O2_P4,F7_F3,C3_F3,F8_F4,C4_F4,T5_P3,O1_P3]\n",
    "df_bipolar = pd.concat(frames,axis=1)\n",
    "df_bipolar.columns = ['T6_P4','O2_P4','F7_F3','C3_F3','F8_F4','C4_F4','T5_P3','O1_P3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#读取文件中的内容。注意和通常读取数据的区别之处\n",
    "df=open('D:/desk/EEG/Rogerio_mice/rogerio_updated_0926/Rogerio_updated_P24.pickle','rb')#注意此处是rb\n",
    "#此处使用的是load(目标文件)\n",
    "data=pickle.load(df)\n",
    "df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=data['C3_F3']\n",
    "df1.columns=['EEG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='D:/desk/EDF/Deployment-flask-master/'\n",
    "f.to_csv(path+'type2_EEG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matlab to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "data = sio.loadmat('D:/desk/EDF/data/sp1s_aa.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=data['x_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=new_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "new_data=numpy.reshape(new_data, (new_data.shape[0]*new_data.shape[2], new_data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "new_data=pd.DataFrame(new_data)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.columns=['F3','F1','Fz','F2','F4','FC5','FC3','FC1','FCz','FC2','FC4','FC6','C5','C3',\n",
    "                  'C1','Cz','C2','C4','C6','CP5','CP3','CP1','CPz','CP2','CP4','CP6','O1','O2']\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# txt to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_fwf('D:/desk/EDF/data/sp1s_aa_train.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pickle to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#读取文件中的内容。注意和通常读取数据的区别之处\n",
    "df=open('F:/Mouse_EEG/Type_II_Rogerio/M/M4-7_P21-28/M4_7/M7_O1_P3.pickle','rb')#注意此处是rb\n",
    "#此处使用的是load(目标文件)\n",
    "data=pickle.load(df)\n",
    "df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=data['EEG2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('mouse1_typeII.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
